var _user$project$Tokenizer$break = F2(
	function (p, xs) {
		var helper = F2(
			function (ys, left) {
				helper:
				while (true) {
					var _p0 = ys;
					if (_p0.ctor === '[]') {
						return {
							ctor: '_Tuple2',
							_0: left,
							_1: {ctor: '[]'}
						};
					} else {
						var _p2 = _p0._1;
						var _p1 = _p0._0;
						if (p(_p1)) {
							return {
								ctor: '_Tuple2',
								_0: _elm_lang$core$List$reverse(
									{ctor: '::', _0: _p1, _1: left}),
								_1: _p2
							};
						} else {
							var _v1 = _p2,
								_v2 = {ctor: '::', _0: _p1, _1: left};
							ys = _v1;
							left = _v2;
							continue helper;
						}
					}
				}
			});
		return A2(
			helper,
			xs,
			{ctor: '[]'});
	});
var _user$project$Tokenizer$removeIndexes = function (xs) {
	return A2(_elm_lang$core$List$map, _elm_lang$core$Tuple$second, xs);
};
var _user$project$Tokenizer$addIndexes = function (xs) {
	var helper = F2(
		function (n, xs) {
			var _p3 = xs;
			if (_p3.ctor === '[]') {
				return {ctor: '[]'};
			} else {
				return {
					ctor: '::',
					_0: {ctor: '_Tuple2', _0: n, _1: _p3._0},
					_1: A2(helper, n + 1, _p3._1)
				};
			}
		});
	return A2(helper, 0, xs);
};
var _user$project$Tokenizer$getCssComment = function (xs) {
	var _p4 = xs;
	if (_p4.ctor === '[]') {
		return _elm_lang$core$Result$Err('getCssComment: Invalid comment');
	} else {
		if (_p4._1.ctor === '::') {
			var _p8 = _p4._1._1;
			var _p7 = _p4._1._0;
			var _p6 = _p4._0;
			if (_elm_lang$core$Native_Utils.eq(
				function (_) {
					return _.ch;
				}(_p6),
				_elm_lang$core$Native_Utils.chr('*')) && _elm_lang$core$Native_Utils.eq(
				function (_) {
					return _.ch;
				}(_p7),
				_elm_lang$core$Native_Utils.chr('/'))) {
				return _elm_lang$core$Result$Ok(
					{
						ctor: '_Tuple2',
						_0: {ctor: '[]'},
						_1: _p8
					});
			} else {
				var _p5 = _user$project$Tokenizer$getCssComment(
					{ctor: '::', _0: _p7, _1: _p8});
				if (_p5.ctor === 'Err') {
					return _elm_lang$core$Result$Err(_p5._0);
				} else {
					return _elm_lang$core$Result$Ok(
						{
							ctor: '_Tuple2',
							_0: {
								ctor: '::',
								_0: _p6,
								_1: {ctor: '::', _0: _p7, _1: _p5._0._0}
							},
							_1: _p5._0._1
						});
				}
			}
		} else {
			var _p9 = _user$project$Tokenizer$getCssComment(_p4._1);
			if (_p9.ctor === 'Err') {
				return _elm_lang$core$Result$Err(_p9._0);
			} else {
				return _elm_lang$core$Result$Ok(
					{
						ctor: '_Tuple2',
						_0: {ctor: '::', _0: _p4._0, _1: _p9._0._0},
						_1: _p9._0._1
					});
			}
		}
	}
};
var _user$project$Tokenizer$getStringLit = function (xs) {
	var _p10 = xs;
	if (_p10.ctor === '[]') {
		return _elm_lang$core$Result$Err('getStringLit: Invalid String literal');
	} else {
		var _p13 = _p10._1;
		var _p12 = _p10._0;
		if (_elm_lang$core$Native_Utils.eq(
			function (_) {
				return _.ch;
			}(_p12),
			_elm_lang$core$Native_Utils.chr('\"'))) {
			return _elm_lang$core$Result$Ok(
				{
					ctor: '_Tuple2',
					_0: {ctor: '[]'},
					_1: _p13
				});
		} else {
			var _p11 = _user$project$Tokenizer$getStringLit(_p13);
			if (_p11.ctor === 'Err') {
				return _elm_lang$core$Result$Err(_p11._0);
			} else {
				return _elm_lang$core$Result$Ok(
					{
						ctor: '_Tuple2',
						_0: {ctor: '::', _0: _p12, _1: _p11._0._0},
						_1: _p11._0._1
					});
			}
		}
	}
};
var _user$project$Tokenizer$isTokenChar = function (c) {
	return _elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('(')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr(')')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('{')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('}')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('+')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('-')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('/')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('*')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr(';')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr(':')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr(',')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('.')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('[')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr(']')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('&')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('|')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('>')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('<')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('=')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('~')) || _elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('#')))))))))))))))))))));
};
var _user$project$Tokenizer$isSpace = function (c) {
	return _elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('\r')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr(' ')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('\t')) || _elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('\n'))));
};
var _user$project$Tokenizer$tokError = function (t) {
	return A2(
		_elm_lang$core$Basics_ops['++'],
		'{ val: ',
		A2(
			_elm_lang$core$Basics_ops['++'],
			function (_) {
				return _.val;
			}(t),
			A2(
				_elm_lang$core$Basics_ops['++'],
				', char ',
				A2(
					_elm_lang$core$Basics_ops['++'],
					_elm_lang$core$Basics$toString(
						function (_) {
							return _.ch;
						}(t)),
					A2(
						_elm_lang$core$Basics_ops['++'],
						', line ',
						A2(
							_elm_lang$core$Basics_ops['++'],
							_elm_lang$core$Basics$toString(
								function (_) {
									return _.ln;
								}(t)),
							' }'))))));
};
var _user$project$Tokenizer$getVal = function (_) {
	return _.val;
};
var _user$project$Tokenizer$Token = F3(
	function (a, b, c) {
		return {val: a, ch: b, ln: c};
	});
var _user$project$Tokenizer$tokenString = function (res) {
	var _p14 = res;
	if (_p14.ctor === 'Err') {
		return _elm_lang$core$Result$Err(_p14._0);
	} else {
		if (_p14._0._0.ctor === '[]') {
			return _elm_lang$core$Result$Err('tokenString: Invalid String literal');
		} else {
			var _p15 = _p14._0._0._0;
			var val = A3(
				_elm_lang$core$List$foldr,
				F2(
					function (c, s) {
						return A2(
							_elm_lang$core$String$cons,
							function (_) {
								return _.ch;
							}(c),
							s);
					}),
				'',
				{ctor: '::', _0: _p15, _1: _p14._0._0._1});
			var ln = function (_) {
				return _.lnp;
			}(_p15);
			var ch = function (_) {
				return _.chp;
			}(_p15);
			return _elm_lang$core$Result$Ok(
				{
					ctor: '_Tuple2',
					_0: A3(
						_user$project$Tokenizer$Token,
						A2(
							_elm_lang$core$Basics_ops['++'],
							'\"',
							A2(_elm_lang$core$Basics_ops['++'], val, '\"')),
						ch,
						ln),
					_1: _p14._0._1
				});
		}
	}
};
var _user$project$Tokenizer$tokenCssComment = function (res) {
	var _p16 = res;
	if (_p16.ctor === 'Err') {
		return _elm_lang$core$Result$Err(_p16._0);
	} else {
		if (_p16._0._0.ctor === '[]') {
			return _elm_lang$core$Result$Err('tokenCssComment: Invalid css comment');
		} else {
			var _p17 = _p16._0._0._0;
			var val = A3(
				_elm_lang$core$List$foldr,
				F2(
					function (c, s) {
						return A2(
							_elm_lang$core$String$cons,
							function (_) {
								return _.ch;
							}(c),
							s);
					}),
				'',
				{ctor: '::', _0: _p17, _1: _p16._0._0._1});
			var ln = function (_) {
				return _.lnp;
			}(_p17);
			var ch = function (_) {
				return _.chp;
			}(_p17);
			return _elm_lang$core$Result$Ok(
				{
					ctor: '_Tuple2',
					_0: A3(
						_user$project$Tokenizer$Token,
						A2(
							_elm_lang$core$Basics_ops['++'],
							'/*',
							A2(_elm_lang$core$Basics_ops['++'], val, '*/')),
						ch,
						ln),
					_1: _p16._0._1
				});
		}
	}
};
var _user$project$Tokenizer$getTokens = function (xs) {
	var tString = function (xs) {
		return _elm_lang$core$String$fromList(
			A2(
				_elm_lang$core$List$map,
				function (_) {
					return _.ch;
				},
				xs));
	};
	var tokenize = function (buff) {
		var ys = _elm_lang$core$List$reverse(buff);
		var _p18 = ys;
		if (_p18.ctor === '[]') {
			return {ctor: '[]'};
		} else {
			var _p19 = _p18._0;
			return {
				ctor: '::',
				_0: A3(
					_user$project$Tokenizer$Token,
					tString(
						{ctor: '::', _0: _p19, _1: _p18._1}),
					function (_) {
						return _.chp;
					}(_p19),
					function (_) {
						return _.lnp;
					}(_p19)),
				_1: {ctor: '[]'}
			};
		}
	};
	var helper = F2(
		function (xs, acc) {
			helper:
			while (true) {
				var _p20 = xs;
				if (_p20.ctor === '[]') {
					return {
						ctor: '_Tuple2',
						_0: tokenize(acc),
						_1: {ctor: '[]'}
					};
				} else {
					var _p22 = _p20._1;
					var _p21 = _p20._0;
					if (_user$project$Tokenizer$isTokenChar(
						function (_) {
							return _.ch;
						}(_p21))) {
						return {
							ctor: '_Tuple2',
							_0: A2(
								_elm_lang$core$Basics_ops['++'],
								tokenize(acc),
								{
									ctor: '::',
									_0: A3(
										_user$project$Tokenizer$Token,
										_elm_lang$core$String$fromChar(
											function (_) {
												return _.ch;
											}(_p21)),
										function (_) {
											return _.chp;
										}(_p21),
										function (_) {
											return _.lnp;
										}(_p21)),
									_1: {ctor: '[]'}
								}),
							_1: _p22
						};
					} else {
						if (_user$project$Tokenizer$isSpace(
							function (_) {
								return _.ch;
							}(_p21))) {
							return {
								ctor: '_Tuple2',
								_0: tokenize(acc),
								_1: _p22
							};
						} else {
							if (_elm_lang$core$Native_Utils.eq(
								function (_) {
									return _.ch;
								}(_p21),
								_elm_lang$core$Native_Utils.chr('\"'))) {
								return {
									ctor: '_Tuple2',
									_0: tokenize(acc),
									_1: {ctor: '::', _0: _p21, _1: _p22}
								};
							} else {
								var _v13 = _p22,
									_v14 = {ctor: '::', _0: _p21, _1: acc};
								xs = _v13;
								acc = _v14;
								continue helper;
							}
						}
					}
				}
			}
		});
	return A2(
		helper,
		xs,
		{ctor: '[]'});
};
var _user$project$Tokenizer$tokenizer_ = function (cs) {
	tokenizer_:
	while (true) {
		var hasStringLitStart = function (s) {
			var _p23 = s;
			if (_p23.ctor === '::') {
				return _elm_lang$core$Native_Utils.eq(
					function (_) {
						return _.ch;
					}(_p23._0),
					_elm_lang$core$Native_Utils.chr('\"')) ? true : false;
			} else {
				return false;
			}
		};
		var hasCommentStart = function (s) {
			var _p24 = s;
			if ((_p24.ctor === '::') && (_p24._1.ctor === '::')) {
				return (_elm_lang$core$Native_Utils.eq(
					function (_) {
						return _.ch;
					}(_p24._0),
					_elm_lang$core$Native_Utils.chr('/')) && _elm_lang$core$Native_Utils.eq(
					function (_) {
						return _.ch;
					}(_p24._1._0),
					_elm_lang$core$Native_Utils.chr('*'))) ? true : false;
			} else {
				return false;
			}
		};
		var _p25 = cs;
		if (_p25.ctor === '[]') {
			return _elm_lang$core$Result$Ok(
				{ctor: '[]'});
		} else {
			var _p33 = _p25._1;
			var _p32 = _p25._0;
			if (hasCommentStart(cs)) {
				var _p26 = _user$project$Tokenizer$tokenCssComment(
					_user$project$Tokenizer$getCssComment(
						A2(_elm_lang$core$List$drop, 2, cs)));
				if (_p26.ctor === 'Err') {
					return _elm_lang$core$Result$Err(_p26._0);
				} else {
					var _p27 = _user$project$Tokenizer$tokenizer_(_p26._0._1);
					if (_p27.ctor === 'Err') {
						return _elm_lang$core$Result$Err(_p27._0);
					} else {
						return _elm_lang$core$Result$Ok(_p27._0);
					}
				}
			} else {
				if (hasStringLitStart(cs)) {
					var _p28 = _user$project$Tokenizer$tokenString(
						_user$project$Tokenizer$getStringLit(_p33));
					if (_p28.ctor === 'Err') {
						return _elm_lang$core$Result$Err(_p28._0);
					} else {
						var _p29 = _user$project$Tokenizer$tokenizer_(_p28._0._1);
						if (_p29.ctor === 'Err') {
							return _elm_lang$core$Result$Err(_p29._0);
						} else {
							return _elm_lang$core$Result$Ok(
								{ctor: '::', _0: _p28._0._0, _1: _p29._0});
						}
					}
				} else {
					if (_user$project$Tokenizer$isSpace(
						function (_) {
							return _.ch;
						}(_p32))) {
						var _v22 = _p33;
						cs = _v22;
						continue tokenizer_;
					} else {
						var _p30 = _user$project$Tokenizer$getTokens(
							{ctor: '::', _0: _p32, _1: _p33});
						var ts = _p30._0;
						var rest = _p30._1;
						var _p31 = _user$project$Tokenizer$tokenizer_(rest);
						if (_p31.ctor === 'Err') {
							return _elm_lang$core$Result$Err(_p31._0);
						} else {
							return _elm_lang$core$Result$Ok(
								A2(_elm_lang$core$Basics_ops['++'], ts, _p31._0));
						}
					}
				}
			}
		}
	}
};
var _user$project$Tokenizer$CharPos = F3(
	function (a, b, c) {
		return {ch: a, lnp: b, chp: c};
	});
var _user$project$Tokenizer$tagPos = function (s) {
	var ls = _user$project$Tokenizer$addIndexes(
		A2(
			_elm_lang$core$List$map,
			function (s) {
				return A2(_elm_lang$core$Basics_ops['++'], s, '\n');
			},
			_elm_lang$core$String$lines(s)));
	var cs = A2(
		_elm_lang$core$List$map,
		function (_p34) {
			var _p35 = _p34;
			return A2(
				_elm_lang$core$List$map,
				function (_p36) {
					var _p37 = _p36;
					return A3(_user$project$Tokenizer$CharPos, _p37._1, _p35._0, _p37._0);
				},
				_user$project$Tokenizer$addIndexes(
					_elm_lang$core$String$toList(_p35._1)));
		},
		ls);
	return _elm_lang$core$List$concat(cs);
};
var _user$project$Tokenizer$tokenizer = function (s) {
	return _user$project$Tokenizer$tokenizer_(
		_user$project$Tokenizer$tagPos(s));
};
