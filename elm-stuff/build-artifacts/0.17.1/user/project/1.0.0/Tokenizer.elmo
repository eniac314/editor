var _user$project$Tokenizer$break = F2(
	function (p, xs) {
		var helper = F2(
			function (ys, left) {
				helper:
				while (true) {
					var _p0 = ys;
					if (_p0.ctor === '[]') {
						return {
							ctor: '_Tuple2',
							_0: left,
							_1: _elm_lang$core$Native_List.fromArray(
								[])
						};
					} else {
						var _p2 = _p0._1;
						var _p1 = _p0._0;
						if (p(_p1)) {
							return {
								ctor: '_Tuple2',
								_0: _elm_lang$core$List$reverse(
									A2(_elm_lang$core$List_ops['::'], _p1, left)),
								_1: _p2
							};
						} else {
							var _v1 = _p2,
								_v2 = A2(_elm_lang$core$List_ops['::'], _p1, left);
							ys = _v1;
							left = _v2;
							continue helper;
						}
					}
				}
			});
		return A2(
			helper,
			xs,
			_elm_lang$core$Native_List.fromArray(
				[]));
	});
var _user$project$Tokenizer$removeIndexes = function (xs) {
	return A2(_elm_lang$core$List$map, _elm_lang$core$Basics$snd, xs);
};
var _user$project$Tokenizer$addIndexes = function (xs) {
	var helper = F2(
		function (n, xs) {
			var _p3 = xs;
			if (_p3.ctor === '[]') {
				return _elm_lang$core$Native_List.fromArray(
					[]);
			} else {
				return A2(
					_elm_lang$core$List_ops['::'],
					{ctor: '_Tuple2', _0: n, _1: _p3._0},
					A2(helper, n + 1, _p3._1));
			}
		});
	return A2(helper, 0, xs);
};
var _user$project$Tokenizer$getStringLit = function (xs) {
	var _p4 = xs;
	if (_p4.ctor === '[]') {
		return _elm_lang$core$Result$Err('getStringLit: Invalid String literal');
	} else {
		var _p7 = _p4._1;
		var _p6 = _p4._0;
		if (_elm_lang$core$Native_Utils.eq(
			function (_) {
				return _.ch;
			}(_p6),
			_elm_lang$core$Native_Utils.chr('\"'))) {
			return _elm_lang$core$Result$Ok(
				{
					ctor: '_Tuple2',
					_0: _elm_lang$core$Native_List.fromArray(
						[]),
					_1: _p7
				});
		} else {
			var _p5 = _user$project$Tokenizer$getStringLit(_p7);
			if (_p5.ctor === 'Err') {
				return _elm_lang$core$Result$Err(_p5._0);
			} else {
				return _elm_lang$core$Result$Ok(
					{
						ctor: '_Tuple2',
						_0: A2(_elm_lang$core$List_ops['::'], _p6, _p5._0._0),
						_1: _p5._0._1
					});
			}
		}
	}
};
var _user$project$Tokenizer$isTokenChar = function (c) {
	return _elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('(')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr(')')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('{')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('}')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('+')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('-')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('/')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('*')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr(';')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr(',')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('.')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('[')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr(']')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('&')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('|')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('>')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('<')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('=')) || _elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('~')))))))))))))))))));
};
var _user$project$Tokenizer$isSpace = function (c) {
	return _elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('\r')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr(' ')) || (_elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('\t')) || _elm_lang$core$Native_Utils.eq(
		c,
		_elm_lang$core$Native_Utils.chr('\n'))));
};
var _user$project$Tokenizer$tokError = function (t) {
	return A2(
		_elm_lang$core$Basics_ops['++'],
		'{ val: ',
		A2(
			_elm_lang$core$Basics_ops['++'],
			function (_) {
				return _.val;
			}(t),
			A2(
				_elm_lang$core$Basics_ops['++'],
				', char ',
				A2(
					_elm_lang$core$Basics_ops['++'],
					_elm_lang$core$Basics$toString(
						function (_) {
							return _.ch;
						}(t)),
					A2(
						_elm_lang$core$Basics_ops['++'],
						', line ',
						A2(
							_elm_lang$core$Basics_ops['++'],
							_elm_lang$core$Basics$toString(
								function (_) {
									return _.ln;
								}(t)),
							' }'))))));
};
var _user$project$Tokenizer$Token = F3(
	function (a, b, c) {
		return {val: a, ch: b, ln: c};
	});
var _user$project$Tokenizer$tokenString = function (xs) {
	var _p8 = xs;
	if (_p8.ctor === 'Err') {
		return _elm_lang$core$Result$Err(_p8._0);
	} else {
		if (_p8._0._0.ctor === '[]') {
			return _elm_lang$core$Result$Err('tokenString: Invalid String literal');
		} else {
			var _p9 = _p8._0._0._0;
			var val = A3(
				_elm_lang$core$List$foldr,
				F2(
					function (c, s) {
						return A2(
							_elm_lang$core$String$cons,
							function (_) {
								return _.ch;
							}(c),
							s);
					}),
				'',
				A2(_elm_lang$core$List_ops['::'], _p9, _p8._0._0._1));
			var ln = function (_) {
				return _.lnp;
			}(_p9);
			var ch = function (_) {
				return _.chp;
			}(_p9);
			return _elm_lang$core$Result$Ok(
				{
					ctor: '_Tuple2',
					_0: A3(
						_user$project$Tokenizer$Token,
						A2(
							_elm_lang$core$Basics_ops['++'],
							'\"',
							A2(_elm_lang$core$Basics_ops['++'], val, '\"')),
						ch,
						ln),
					_1: _p8._0._1
				});
		}
	}
};
var _user$project$Tokenizer$getTokens$ = function (xs) {
	var tString = function (xs) {
		return _elm_lang$core$String$fromList(
			A2(
				_elm_lang$core$List$map,
				function (_) {
					return _.ch;
				},
				xs));
	};
	var tokenize = function (buff) {
		var ys = _elm_lang$core$List$reverse(buff);
		var _p10 = ys;
		if (_p10.ctor === '[]') {
			return _elm_lang$core$Native_List.fromArray(
				[]);
		} else {
			var _p11 = _p10._0;
			return _elm_lang$core$Native_List.fromArray(
				[
					A3(
					_user$project$Tokenizer$Token,
					tString(
						A2(_elm_lang$core$List_ops['::'], _p11, _p10._1)),
					function (_) {
						return _.chp;
					}(_p11),
					function (_) {
						return _.lnp;
					}(_p11))
				]);
		}
	};
	var helper = F2(
		function (xs, acc) {
			helper:
			while (true) {
				var _p12 = xs;
				if (_p12.ctor === '[]') {
					return {
						ctor: '_Tuple2',
						_0: tokenize(acc),
						_1: _elm_lang$core$Native_List.fromArray(
							[])
					};
				} else {
					var _p14 = _p12._1;
					var _p13 = _p12._0;
					if (_user$project$Tokenizer$isTokenChar(
						function (_) {
							return _.ch;
						}(_p13))) {
						return {
							ctor: '_Tuple2',
							_0: A2(
								_elm_lang$core$Basics_ops['++'],
								tokenize(acc),
								_elm_lang$core$Native_List.fromArray(
									[
										A3(
										_user$project$Tokenizer$Token,
										_elm_lang$core$String$fromChar(
											function (_) {
												return _.ch;
											}(_p13)),
										function (_) {
											return _.chp;
										}(_p13),
										function (_) {
											return _.lnp;
										}(_p13))
									])),
							_1: _p14
						};
					} else {
						if (_user$project$Tokenizer$isSpace(
							function (_) {
								return _.ch;
							}(_p13))) {
							return {
								ctor: '_Tuple2',
								_0: tokenize(acc),
								_1: _p14
							};
						} else {
							if (_elm_lang$core$Native_Utils.eq(
								function (_) {
									return _.ch;
								}(_p13),
								_elm_lang$core$Native_Utils.chr('\"'))) {
								return {
									ctor: '_Tuple2',
									_0: tokenize(acc),
									_1: A2(_elm_lang$core$List_ops['::'], _p13, _p14)
								};
							} else {
								var _v9 = _p14,
									_v10 = A2(_elm_lang$core$List_ops['::'], _p13, acc);
								xs = _v9;
								acc = _v10;
								continue helper;
							}
						}
					}
				}
			}
		});
	return A2(
		helper,
		xs,
		_elm_lang$core$Native_List.fromArray(
			[]));
};
var _user$project$Tokenizer$tokenizer$ = function (cs) {
	tokenizer$:
	while (true) {
		var _p15 = cs;
		if (_p15.ctor === '[]') {
			return _elm_lang$core$Result$Ok(
				_elm_lang$core$Native_List.fromArray(
					[]));
		} else {
			var _p21 = _p15._1;
			var _p20 = _p15._0;
			if (_elm_lang$core$Native_Utils.eq(
				function (_) {
					return _.ch;
				}(_p20),
				_elm_lang$core$Native_Utils.chr('\"'))) {
				var _p16 = _user$project$Tokenizer$tokenString(
					_user$project$Tokenizer$getStringLit(_p21));
				if (_p16.ctor === 'Err') {
					return _elm_lang$core$Result$Err(_p16._0);
				} else {
					var _p17 = _user$project$Tokenizer$tokenizer$(_p16._0._1);
					if (_p17.ctor === 'Err') {
						return _elm_lang$core$Result$Err(_p17._0);
					} else {
						return _elm_lang$core$Result$Ok(
							A2(_elm_lang$core$List_ops['::'], _p16._0._0, _p17._0));
					}
				}
			} else {
				if (_user$project$Tokenizer$isSpace(
					function (_) {
						return _.ch;
					}(_p20))) {
					var _v14 = _p21;
					cs = _v14;
					continue tokenizer$;
				} else {
					var _p18 = _user$project$Tokenizer$getTokens$(
						A2(_elm_lang$core$List_ops['::'], _p20, _p21));
					var ts = _p18._0;
					var rest = _p18._1;
					var _p19 = _user$project$Tokenizer$tokenizer$(rest);
					if (_p19.ctor === 'Err') {
						return _elm_lang$core$Result$Err(_p19._0);
					} else {
						return _elm_lang$core$Result$Ok(
							A2(_elm_lang$core$Basics_ops['++'], ts, _p19._0));
					}
				}
			}
		}
	}
};
var _user$project$Tokenizer$CharPos = F3(
	function (a, b, c) {
		return {ch: a, lnp: b, chp: c};
	});
var _user$project$Tokenizer$tagPos = function (s) {
	var ls = _user$project$Tokenizer$addIndexes(
		_elm_lang$core$String$lines(s));
	var cs = A2(
		_elm_lang$core$List$map,
		function (_p22) {
			var _p23 = _p22;
			return A2(
				_elm_lang$core$List$map,
				function (_p24) {
					var _p25 = _p24;
					return A3(_user$project$Tokenizer$CharPos, _p25._1, _p23._0, _p25._0);
				},
				_user$project$Tokenizer$addIndexes(
					_elm_lang$core$String$toList(_p23._1)));
		},
		ls);
	return _elm_lang$core$List$concat(cs);
};
var _user$project$Tokenizer$tokenizer = function (s) {
	return _user$project$Tokenizer$tokenizer$(
		_user$project$Tokenizer$tagPos(s));
};
